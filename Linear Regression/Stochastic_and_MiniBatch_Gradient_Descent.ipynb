{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpM3OXDOY2n7/ZJUJ6nWe+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Susovan88/Machine_Learning/blob/main/Linear%20Regression/Stochastic_and_MiniBatch_Gradient_Descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4ghdvyDB3ps",
        "outputId": "148a5e3c-20f0-451d-f546-f6f2507fe8e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(442, 10) (442,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "import numpy as np\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import time\n",
        "import random\n",
        "\n",
        "x,y=load_diabetes(return_X_y=True)\n",
        "\n",
        "print(x.shape,y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2)\n",
        "\n",
        "st=time.time()\n",
        "\n",
        "reg=LinearRegression()\n",
        "reg.fit(x_train,y_train)\n",
        "\n",
        "print(\"time takes ->\", time.time()-st)\n",
        "\n",
        "print(reg.coef_ ,reg.intercept_)\n",
        "\n",
        "y_pred=reg.predict(x_test)\n",
        "print(\"r2 score -> \",r2_score(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFYsEpnrI8KC",
        "outputId": "d2230a7a-3513-4b1c-ba30-5059d5517017"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time takes -> 0.005373716354370117\n",
            "[  -9.15865318 -205.45432163  516.69374454  340.61999905 -895.5520019\n",
            "  561.22067904  153.89310954  126.73139688  861.12700152   52.42112238] 151.88331005254167\n",
            "r2 score ->  0.4399338661568968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stochastic Gradient Descent**:\n",
        "\n",
        "Uses only 1 random sample at a time to compute gradient and update parameters.\n",
        "\n",
        "Update happens for each sample.\n",
        "\n",
        "ðŸ“Œ Example:\n",
        "Suppose 1000 data points.\n",
        "\n",
        "Pick 1 data point â†’ update weights.\n",
        "\n",
        "Pick next data point â†’ update again.\n",
        "\n",
        "Repeats 1000 times per epoch.\n",
        "\n",
        "âœ… Pros: Faster updates, can escape local minima.\n",
        "\n",
        "âŒ Cons: Very noisy updates, may â€œbounceâ€ around optimum."
      ],
      "metadata": {
        "id": "kHewCP90JOqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Me05F6DiW3us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StochasticDGR:\n",
        "  def __init__(self,learning_rate,epochs=50):\n",
        "    self.learning_rate=learning_rate\n",
        "    self.epochs=epochs\n",
        "    self.coef_=None\n",
        "    self.intercept_=None\n",
        "\n",
        "  def fit(self,x_train,y_train):\n",
        "    self.intercept_=0\n",
        "    self.coef_=np.ones(x_train.shape[1])\n",
        "\n",
        "    for i in range(self.epochs):\n",
        "      for j in range(x_train.shape[0]):\n",
        "        idx=np.random.randint(0,x_train.shape[0]) ## random index\n",
        "\n",
        "        y_cap=np.dot(x_train[idx],self.coef_)+self.intercept_\n",
        "        intercept_diff=-2*(y_train[idx]-y_cap)\n",
        "        self.intercept_=self.intercept_-(self.learning_rate * intercept_diff)\n",
        "\n",
        "        coef_diff=-2 * np.dot((y_train[idx]-y_cap),x_train[idx])\n",
        "        self.coef_=self.coef_-(self.learning_rate* coef_diff)\n",
        "\n",
        "    print(\"intercept_ -> \",self.intercept_)\n",
        "    print(\"coef_ -> \",self.coef_)\n",
        "\n",
        "  def predict(self,x_test):\n",
        "    return np.dot(x_test,self.coef_)+self.intercept_\n"
      ],
      "metadata": {
        "id": "M_vl6EMmJLLp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st=time.time()\n",
        "\n",
        "sgd=StochasticDGR(0.01,50)\n",
        "sgd.fit(x_train,y_train)\n",
        "\n",
        "print(\"time takes ->\", time.time()-st)\n",
        "\n",
        "y_pred=sgd.predict(x_test)\n",
        "print(\"r2 score -> \",r2_score(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ez7rP4nxR3zj",
        "outputId": "df160f52-a9a8-4a44-c0d5-f9367cc4db6c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "intercept_ ->  154.12237709236007\n",
            "coef_ ->  [  55.32283926  -67.8570262   350.06049801  243.41546453    9.24196429\n",
            "  -32.69348633 -178.06601024  131.56950897  315.85384302  126.0698431 ]\n",
            "time takes -> 0.21212029457092285\n",
            "r2 score ->  0.4348347947492889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape,sgd.coef_.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B4tLUpAS5B3",
        "outputId": "1518ad2f-9931-45cf-adec-25873787879d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((89, 10), (10,))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "sgd = SGDRegressor(max_iter=90, learning_rate='constant', eta0=0.01)\n",
        "\n",
        "# Fit the model\n",
        "sgd.fit(x_train, y_train)\n",
        "\n",
        "# Now you can predict\n",
        "y_pred = sgd.predict(x_test)\n",
        "\n",
        "print(\"r2 score -> \", r2_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGfLYi2kVgBu",
        "outputId": "b5a2ed45-7034-4f3c-979b-03ae463265a1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r2 score ->  0.42664387198535625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1608: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mini-Batch Gradient Descent (most popular ðŸš€)**\n",
        "\n",
        "Uses a small batch (subset) of data (like 32, 64, 128 samples) to compute gradient and update.\n",
        "\n",
        "Update happens per batch.\n",
        "\n",
        "ðŸ“Œ Example:\n",
        "Suppose 1000 data points, batch size = 100.\n",
        "\n",
        "First 100 â†’ compute gradient â†’ update.\n",
        "\n",
        "Next 100 â†’ update again.\n",
        "\n",
        "So 10 updates per epoch.\n",
        "\n",
        "âœ… Pros: Balance between speed & stability.\n",
        "âœ… Works best with GPUs (parallel computation).\n",
        "âŒ Slightly less accurate than full batch, but much faster."
      ],
      "metadata": {
        "id": "RLLW-OklhlSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MiniBatchDGR:\n",
        "  def __init__(self,learning_rate,batch_size,epochs=50):\n",
        "    self.learning_rate=learning_rate\n",
        "    self.epochs=epochs\n",
        "    self.batch_size=batch_size\n",
        "    self.coef_=None\n",
        "    self.intercept_=None\n",
        "\n",
        "  def fit(self,x_train,y_train):\n",
        "    self.intercept_=0\n",
        "    self.coef_=np.ones(x_train.shape[1])\n",
        "\n",
        "    for i in range(self.epochs):\n",
        "      for j in range(int(x_train.shape[0]/self.batch_size)):\n",
        "        idxs=random.sample(range(0,x_train.shape[0]),self.batch_size)  ## random indexs\n",
        "\n",
        "        y_cap=np.dot(x_train[idxs],self.coef_)+self.intercept_\n",
        "        intercept_diff=-2*np.mean(y_train[idxs]-y_cap)\n",
        "        self.intercept_=self.intercept_-(self.learning_rate * intercept_diff)\n",
        "\n",
        "        coef_diff=-2 * np.dot((y_train[idxs]-y_cap),x_train[idxs])\n",
        "        self.coef_=self.coef_-(self.learning_rate* coef_diff)\n",
        "\n",
        "    print(\"intercept_ -> \",self.intercept_)\n",
        "    print(\"coef_ -> \",self.coef_)\n",
        "\n",
        "  def predict(self,x_test):\n",
        "    return np.dot(x_test,self.coef_)+self.intercept_"
      ],
      "metadata": {
        "id": "PU2dYQ0Zhh-o"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mBgd=MiniBatchDGR(0.05,35,50)\n",
        "mBgd.fit(x_train,y_train)\n",
        "\n",
        "y_pred=mBgd.predict(x_test)\n",
        "print(\"r2 score -> \",r2_score(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y50QqXbDkjmM",
        "outputId": "4e988522-c904-4681-f27c-95e1d8d1accf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "intercept_ ->  151.66867372970202\n",
            "coef_ ->  [  -1.58710876 -199.80902407  513.67470919  339.42296811  -62.17689375\n",
            " -140.14879445 -197.48012816   86.97636538  511.64217417   87.32257704]\n",
            "r2 score ->  0.44660068671052766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTyUrAsxleOt",
        "outputId": "21bd8851-da6d-4421-cc2b-2be909a3b38b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([330,  15, 176,  23, 113, 352, 265,  67, 349,  66])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "mBgd = SGDRegressor(learning_rate='constant', eta0=0.2)\n",
        "\n",
        "# Fit the model -> miniBatch_GD\n",
        "batch_size=50\n",
        "epochs=50\n",
        "for i in range(epochs):\n",
        "  idxs=random.sample(range(x_train.shape[0]),batch_size)\n",
        "  mBgd.partial_fit(x_train[idxs],y_train[idxs])\n",
        "\n",
        "# Now you can predict\n",
        "y_pred = mBgd.predict(x_test)\n",
        "\n",
        "print(\"r2 score -> \", r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGUviucAor7Z",
        "outputId": "42c56680-0ac2-4a16-824d-757580663de4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r2 score ->  0.4435140659732463\n"
          ]
        }
      ]
    }
  ]
}